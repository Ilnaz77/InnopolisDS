{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import random\n",
    "from torchvision import transforms, models, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import cv2\n",
    "\n",
    "import PIL.Image as Image\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(filename, num_of_frames=100):\n",
    "    \"\"\"input: \n",
    "            Video name - имя файла в текущей папке, \n",
    "            Num_of_frames - число фрэймов\n",
    "       output: \n",
    "            FloatTensor [T, C, H, W]\n",
    "    \"\"\"\n",
    "    return torchvision.io.read_video(filename, pts_unit='sec')[0][:num_of_frames].permute(0,3,1,2).type(torch.FloatTensor)\n",
    "\n",
    "def write_video(filename, video_array, fps=1):\n",
    "    \"\"\"Записывает тензор в формате [T, C, H, W] в видеофайл.\n",
    "       input:\n",
    "           filename - путь для save видео\n",
    "           video_array - тензор [T, C, H, W]\n",
    "           fps - число кадров в секунду\n",
    "    \"\"\"\n",
    "    torchvision.io.write_video(filename, video_array.permute(0,2,3,1).type(torch.uint8), fps)\n",
    "    \n",
    "def show_frame(input_tensor, title=''):\n",
    "    \"\"\"Функция для отрисовки кадров.\n",
    "       input:\n",
    "           Любой тензор [1,C,H,W]\n",
    "    \"\"\"\n",
    "    image = input_tensor.permute(1, 2, 0).numpy()\n",
    "    plt.imshow((image).astype(np.uint8))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "def set_random_seed(seed=0):\n",
    "    \"\"\"Сделаем систему детерминированной.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def get_device():\n",
    "    \"\"\"Если система поддерживает CUDA, то вернет GPU\n",
    "       иначе вернет CPU. Нужно для закидывания модели и тензоров в GPU.\n",
    "       Потом можно к любому тензору, модели применять .to(get_device())\"\"\"\n",
    "    global device\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3, 1080, 1920])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_random_seed(0)\n",
    "video = read_video('test.mp4')\n",
    "video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True).to(get_device())\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тут у меня в общем ошибка у rectangle, потом гляну почему так\n",
    "# Еще потом реализую класс Dataset, чтобы его передать в Dataloader. Это надо, чтобы создать батчи для трэйн.тест.\n",
    "# Но пока думаю нет смысла в батчевании, потом когда дадут датасет.\n",
    "# Потом я нашел туториал, где можно fasterrcnn_resnet50_fpn докрутить"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type tuple)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-233-9c3ac4120c1a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mdetect_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-233-9c3ac4120c1a>\u001b[0m in \u001b[0;36mdetect_obj\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#         print(point1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m#         print(point2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrectangle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mToPILImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: an integer is required (got type tuple)"
     ]
    }
   ],
   "source": [
    "def detect_obj(image):\n",
    "#     tensor_image = torch.tensor(image)\n",
    "#     tensor_image = tensor_image.permute(2, 0, 1)\n",
    "    img_01 = image / 255.\n",
    "    model.eval()\n",
    "    predictions = model([img_01])\n",
    "#     print(predictions[0]['scores'])\n",
    "#     print(predictions[0]['boxes'][0])\n",
    "    if predictions[0]['scores'][0] > 0.5:\n",
    "        box = predictions[0]['boxes'][0]\n",
    "        point1 = (round(box[0].item()), round(box[1].item()))\n",
    "        point2 = (round(box[2].item()), round(box[3].item()))\n",
    "#         print(point1)\n",
    "#         print(point2)\n",
    "        image = cv2.rectangle(ToPILImage(image), (int(point1[0]), int(point1[1])), (int(point2[0]), int(point2[1])), (255,0,0), 2)\n",
    "    return image\n",
    "\n",
    "\n",
    "detect_obj(video[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
